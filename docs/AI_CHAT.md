

Встроенный AI помощник для общения прямо в группе управления ботом.



- **Естественное общение** с AI на русском языке
- **Множество форматов** вопросов
- **Интеграция с Ollama** - без лимитов
- **Контекстные ответы** на любые вопросы




- `/ask ваш вопрос` - задать вопрос AI
- `/ai_info` - информация об AI системе


- `AI: ваш вопрос`
- `ИИ: ваш вопрос`  
- `АИ: ваш вопрос`



```
/ask Какая погода в Москве?

AI: Объясни что такое блокчейн простыми словами

ИИ: Напиши короткий стих про осень

/ask Помоги составить план статьи про новости

AI: Что означает аббревиатура СМИ?
```




- **AIChatHandler** - основной обработчик диалогов
- **Интеграция с Ollama** - использует существующий AI детектор
- **Форматирование ответов** - красивое отображение в Telegram


- Доступ только **авторизованным пользователям**
- Ограничение длины ответов **(3000 символов)**
- Обработка ошибок и **fallback**


- **Кэширование** модели в памяти
- **Асинхронная** обработка запросов
- **Timeout защита** от зависания



AI чат использует существующую конфигурацию Ollama из `config.yaml`:

```yaml
ai:
  enabled: true
  urgency_detection:
    enabled: true
  ollama:
    url: "http://localhost:11434"
    model: "qwen2.5:7b"
    timeout_seconds: 30
```




1. Проверьте, что **Ollama запущен**: `ollama ps`
2. Убедитесь, что **модель загружена**: `ollama list`
3. Проверьте **логи бота** на ошибки


- **Первый запрос** загружает модель (~30 сек)
- **Последующие** запросы быстрые (~2-5 сек)
- Используйте `ollama serve` для постоянной работы


- Проверьте **URL Ollama** в конфиге
- Убедитесь в **доступности порта 11434**
- Перезапустите **Ollama сервис**



- **Контекстная память** диалогов
- **Специализированные** промпты для СМИ
- **Интеграция** с базой знаний
- **Голосовые** ответы (TTS)
- **Поддержка файлов** и изображений
